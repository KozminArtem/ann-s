{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b026b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import BatchNorm2d\n",
    "\n",
    "# from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "39e63fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels = 2, out_channels = 4,\\\n",
    "                            kernel_size = (2, 6), stride = (2,2))#2 - height, 6 - width \n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(3, 3), stride=(3, 3)) #stride = step\n",
    "        \n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = Conv2d(in_channels=4, out_channels=8,\\\n",
    "                            kernel_size=(4, 4))\n",
    "        self.relu2 = ReLU()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(3, 3), stride=(3, 3))\n",
    "        \n",
    "        \n",
    "        # initialize third set of CONV => RELU => POOL layers\n",
    "        self.conv3 = Conv2d(in_channels=8, out_channels=16,\\\n",
    "                            kernel_size=(3, 3))\n",
    "        self.relu3 = ReLU()\n",
    "        self.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=32, out_features=8)\n",
    "        self.relu4 = ReLU()\n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = Linear(in_features=8, out_features=1)\n",
    "#         self.logSoftmax = LogSoftmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "#         print(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        # pass the output from the previous layer through the second\n",
    "        # set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # pass the output from the previous layer through the second\n",
    "        # set of CONV => RELU => POOL layers\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "\n",
    "        # flatten the output from the previous layer and pass it\n",
    "        # through our only set of FC => RELU layers\n",
    "\n",
    "        x = flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        # pass the output to our softmax classifier to get our output\n",
    "        # predictions\n",
    "        output = self.fc2(x)\n",
    "    #     output = self.logSoftmax(x)\n",
    "        # return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1059a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels = 2, out_channels = 4,\\\n",
    "                            kernel_size = (4, 10), stride = (4,5))#2 - height, 6 - width \n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(4, 3), stride=(4, 3)) #stride = step\n",
    "        \n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=48, out_features=8)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc2 = Linear(in_features=8, out_features=3)\n",
    "        self.relu3 = ReLU()\n",
    "        # initialize our softmax classifier\n",
    "        self.fc3 = Linear(in_features=3, out_features=1)\n",
    "#         self.logSoftmax = LogSoftmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "#         print(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = flatten(x, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        output = self.fc3(x)\n",
    "    #     output = self.logSoftmax(x)\n",
    "        # return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4bf4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.norm1 = BatchNorm2d(2)\n",
    "\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels = 2, out_channels = 8,\\\n",
    "                            kernel_size = (16, 20), stride = (16,10))#2 - height, 6 - width \n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) #stride = step\n",
    "        \n",
    "#         self.norm2 = BatchNorm2d(8)\n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=32, out_features=8)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc2 = Linear(in_features=8, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "#         print(x)\n",
    "        x = self.norm1(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = flatten(x, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26d4cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e417f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "326d914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "        target_954 = np.load('data_segment/Y_natur_954.npz')\n",
    "        for j in range(3000):\n",
    "            self.data.append([\"data_segment/natur_X/954_\" + str(j) + '.npz',target_954['arr_0'][j]])\n",
    "#         print(self.data)\n",
    "\n",
    "        target_9_7 = np.load('data_segment/Y_natur_9_7.npz')\n",
    "#         print(target_9_7['arr_0'])\n",
    "        for j in range(3000):\n",
    "            self.data.append([\"data_segment/natur_X/9_7_\" + str(j) + '.npz',target_9_7['arr_0'][j]])\n",
    "\n",
    "        \n",
    "        target_Air = np.load('data_segment/Y_natur_Air.npz')\n",
    "#         print(target_Air['arr_0'])\n",
    "        for j in range(3000):\n",
    "            self.data.append([\"data_segment/natur_X/Air_\" + str(j) + '.npz',target_Air['arr_0'][j]])\n",
    "        \n",
    "        temp = np.load('data_segment/natur_X/954_0.npz')\n",
    "        self.img_dim = temp['arr_0'].shape  \n",
    "        print(self.img_dim)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)    \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.data[idx]\n",
    "        \n",
    "        img = np.load(img_path)\n",
    "        img_tensor = torch.from_numpy(img['arr_0'])\n",
    "        \n",
    "        target_tensor = torch.tensor(target)\n",
    "#         print(target_tensor, target)\n",
    "        \n",
    "#         img_tensor = img_tensor.permute(2, 0, 1)\n",
    "#         class_id = torch.tensor([class_id])\n",
    "        \n",
    "        return img_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53786f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 50)\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "data = CustomDataset()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c8ff5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 50])\n",
      "torch.DoubleTensor\n",
      "torch.DoubleTensor\n",
      "tensor(0.0319, dtype=torch.float64) 0.03186977247219236\n"
     ]
    }
   ],
   "source": [
    "print(data[1][0].size())\n",
    "print(data[1][0].type())\n",
    "print(data[1][1].type())\n",
    "print(data[1][1], data[1][1].item())\n",
    "# print(data[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3308167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_split = 0.7\n",
    "Val_split = 0.15\n",
    "Test_split = 0.15\n",
    "\n",
    "(trainData, valData, testData) = random_split(data, [Train_split, Val_split, Test_split],\\\n",
    "                                              generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44596b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300\n",
      "1350\n",
      "1350\n"
     ]
    }
   ],
   "source": [
    "print(len(trainData))\n",
    "print(len(valData))\n",
    "print(len(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a2d5bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# print(testDataLoader.dataset[0])\n",
    "\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "print(trainSteps)\n",
    "\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE\n",
    "print(valSteps)\n",
    "\n",
    "testSteps = len(testDataLoader.dataset) // BATCH_SIZE\n",
    "print(testSteps)\n",
    "\n",
    "\n",
    "# print(trainDataLoader.dataset)\n",
    "# print(trainDataLoader.dataset[1])\n",
    "# print(trainDataLoader.dataset[1][0].type())\n",
    "# print(trainDataLoader.dataset[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "baeee3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the LeNet model...\n",
      "LeNet(\n",
      "  (norm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(2, 8, kernel_size=(16, 20), stride=(16, 10))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define training hyperparameters\n",
    "INIT_LR = 0.001\n",
    "\n",
    "# initialize the LeNet model\n",
    "print(\"[INFO] initializing the LeNet model...\")\n",
    "\n",
    "model = LeNet().to(device)\n",
    "# model.type(torch.cuda.DoubleTensor)\n",
    "model.type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "print(model)\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(opt, 'min')\n",
    "\n",
    "\n",
    "\n",
    "lossMSE = nn.MSELoss()\n",
    "# lossMAE = nn.L1Loss()\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [],\"val_loss\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d9cc0660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n",
      "[INFO] EPOCH: 1/100\n",
      "Train loss: 0.003766, Val loss: 0.002662\n",
      "[INFO] EPOCH: 2/100\n",
      "Train loss: 0.003264, Val loss: 0.005787\n",
      "[INFO] EPOCH: 3/100\n",
      "Train loss: 0.003875, Val loss: 0.003953\n",
      "[INFO] EPOCH: 4/100\n",
      "Train loss: 0.003342, Val loss: 0.002920\n",
      "[INFO] EPOCH: 5/100\n",
      "Train loss: 0.003017, Val loss: 0.001892\n",
      "[INFO] EPOCH: 6/100\n",
      "Train loss: 0.002663, Val loss: 0.003009\n",
      "[INFO] EPOCH: 7/100\n",
      "Train loss: 0.002838, Val loss: 0.001645\n",
      "[INFO] EPOCH: 8/100\n",
      "Train loss: 0.002383, Val loss: 0.001701\n",
      "[INFO] EPOCH: 9/100\n",
      "Train loss: 0.002338, Val loss: 0.002109\n",
      "[INFO] EPOCH: 10/100\n",
      "Train loss: 0.002469, Val loss: 0.001688\n",
      "[INFO] EPOCH: 11/100\n",
      "Train loss: 0.002447, Val loss: 0.003465\n",
      "[INFO] EPOCH: 12/100\n",
      "Train loss: 0.002648, Val loss: 0.001637\n",
      "[INFO] EPOCH: 13/100\n",
      "Train loss: 0.001965, Val loss: 0.002562\n",
      "[INFO] EPOCH: 14/100\n",
      "Train loss: 0.002201, Val loss: 0.001932\n",
      "[INFO] EPOCH: 15/100\n",
      "Train loss: 0.001950, Val loss: 0.002004\n",
      "[INFO] EPOCH: 16/100\n",
      "Train loss: 0.001835, Val loss: 0.001636\n",
      "[INFO] EPOCH: 17/100\n",
      "Train loss: 0.001725, Val loss: 0.001101\n",
      "[INFO] EPOCH: 18/100\n",
      "Train loss: 0.001857, Val loss: 0.001559\n",
      "[INFO] EPOCH: 19/100\n",
      "Train loss: 0.001898, Val loss: 0.001998\n",
      "[INFO] EPOCH: 20/100\n",
      "Train loss: 0.001625, Val loss: 0.001568\n",
      "[INFO] EPOCH: 21/100\n",
      "Train loss: 0.001318, Val loss: 0.001122\n",
      "[INFO] EPOCH: 22/100\n",
      "Train loss: 0.001268, Val loss: 0.001251\n",
      "[INFO] EPOCH: 23/100\n",
      "Train loss: 0.001413, Val loss: 0.001426\n",
      "[INFO] EPOCH: 24/100\n",
      "Train loss: 0.001492, Val loss: 0.001434\n",
      "[INFO] EPOCH: 25/100\n",
      "Train loss: 0.001497, Val loss: 0.001647\n",
      "[INFO] EPOCH: 26/100\n",
      "Train loss: 0.002636, Val loss: 0.001847\n",
      "[INFO] EPOCH: 27/100\n",
      "Train loss: 0.001651, Val loss: 0.001244\n",
      "[INFO] EPOCH: 28/100\n",
      "Train loss: 0.001162, Val loss: 0.000959\n",
      "[INFO] EPOCH: 29/100\n",
      "Train loss: 0.001011, Val loss: 0.001262\n",
      "[INFO] EPOCH: 30/100\n",
      "Train loss: 0.000962, Val loss: 0.000816\n",
      "[INFO] EPOCH: 31/100\n",
      "Train loss: 0.000836, Val loss: 0.000583\n",
      "[INFO] EPOCH: 32/100\n",
      "Train loss: 0.000923, Val loss: 0.000706\n",
      "[INFO] EPOCH: 33/100\n",
      "Train loss: 0.000828, Val loss: 0.000595\n",
      "[INFO] EPOCH: 34/100\n",
      "Train loss: 0.000801, Val loss: 0.000639\n",
      "[INFO] EPOCH: 35/100\n",
      "Train loss: 0.000815, Val loss: 0.000870\n",
      "[INFO] EPOCH: 36/100\n",
      "Train loss: 0.000721, Val loss: 0.000565\n",
      "[INFO] EPOCH: 37/100\n",
      "Train loss: 0.000695, Val loss: 0.000526\n",
      "[INFO] EPOCH: 38/100\n",
      "Train loss: 0.000642, Val loss: 0.000502\n",
      "[INFO] EPOCH: 39/100\n",
      "Train loss: 0.000658, Val loss: 0.000722\n",
      "[INFO] EPOCH: 40/100\n",
      "Train loss: 0.000813, Val loss: 0.001090\n",
      "[INFO] EPOCH: 41/100\n",
      "Train loss: 0.000790, Val loss: 0.000979\n",
      "[INFO] EPOCH: 42/100\n",
      "Train loss: 0.000585, Val loss: 0.000515\n",
      "[INFO] EPOCH: 43/100\n",
      "Train loss: 0.000560, Val loss: 0.000550\n",
      "[INFO] EPOCH: 44/100\n",
      "Train loss: 0.000575, Val loss: 0.000514\n",
      "[INFO] EPOCH: 45/100\n",
      "Train loss: 0.000487, Val loss: 0.000941\n",
      "[INFO] EPOCH: 46/100\n",
      "Train loss: 0.000603, Val loss: 0.000485\n",
      "[INFO] EPOCH: 47/100\n",
      "Train loss: 0.000525, Val loss: 0.000587\n",
      "[INFO] EPOCH: 48/100\n",
      "Train loss: 0.000536, Val loss: 0.000521\n",
      "[INFO] EPOCH: 49/100\n",
      "Train loss: 0.000418, Val loss: 0.000676\n",
      "[INFO] EPOCH: 50/100\n",
      "Train loss: 0.000386, Val loss: 0.000472\n",
      "[INFO] EPOCH: 51/100\n",
      "Train loss: 0.000606, Val loss: 0.000773\n",
      "[INFO] EPOCH: 52/100\n",
      "Train loss: 0.001230, Val loss: 0.000485\n",
      "[INFO] EPOCH: 53/100\n",
      "Train loss: 0.000374, Val loss: 0.000349\n",
      "[INFO] EPOCH: 54/100\n",
      "Train loss: 0.000330, Val loss: 0.000371\n",
      "[INFO] EPOCH: 55/100\n",
      "Train loss: 0.000350, Val loss: 0.000463\n",
      "[INFO] EPOCH: 56/100\n",
      "Train loss: 0.000322, Val loss: 0.000264\n",
      "[INFO] EPOCH: 57/100\n",
      "Train loss: 0.000314, Val loss: 0.000350\n",
      "[INFO] EPOCH: 58/100\n",
      "Train loss: 0.000335, Val loss: 0.000460\n",
      "[INFO] EPOCH: 59/100\n",
      "Train loss: 0.000453, Val loss: 0.000707\n",
      "[INFO] EPOCH: 60/100\n",
      "Train loss: 0.000489, Val loss: 0.000300\n",
      "[INFO] EPOCH: 61/100\n",
      "Train loss: 0.000307, Val loss: 0.000226\n",
      "[INFO] EPOCH: 62/100\n",
      "Train loss: 0.000291, Val loss: 0.000257\n",
      "[INFO] EPOCH: 63/100\n",
      "Train loss: 0.000331, Val loss: 0.000466\n",
      "[INFO] EPOCH: 64/100\n",
      "Train loss: 0.000420, Val loss: 0.000492\n",
      "[INFO] EPOCH: 65/100\n",
      "Train loss: 0.000819, Val loss: 0.000498\n",
      "[INFO] EPOCH: 66/100\n",
      "Train loss: 0.000261, Val loss: 0.000262\n",
      "[INFO] EPOCH: 67/100\n",
      "Train loss: 0.000245, Val loss: 0.000219\n",
      "[INFO] EPOCH: 68/100\n",
      "Train loss: 0.000216, Val loss: 0.000190\n",
      "[INFO] EPOCH: 69/100\n",
      "Train loss: 0.000220, Val loss: 0.000207\n",
      "[INFO] EPOCH: 70/100\n",
      "Train loss: 0.000207, Val loss: 0.000242\n",
      "[INFO] EPOCH: 71/100\n",
      "Train loss: 0.000242, Val loss: 0.000207\n",
      "[INFO] EPOCH: 72/100\n",
      "Train loss: 0.000228, Val loss: 0.000277\n",
      "[INFO] EPOCH: 73/100\n",
      "Train loss: 0.000224, Val loss: 0.000274\n",
      "[INFO] EPOCH: 74/100\n",
      "Train loss: 0.000206, Val loss: 0.000205\n",
      "[INFO] EPOCH: 75/100\n",
      "Train loss: 0.000228, Val loss: 0.000206\n",
      "[INFO] EPOCH: 76/100\n",
      "Train loss: 0.000651, Val loss: 0.000752\n",
      "[INFO] EPOCH: 77/100\n",
      "Train loss: 0.000544, Val loss: 0.000220\n",
      "[INFO] EPOCH: 78/100\n",
      "Train loss: 0.000246, Val loss: 0.000228\n",
      "[INFO] EPOCH: 79/100\n",
      "Train loss: 0.000213, Val loss: 0.000180\n",
      "[INFO] EPOCH: 80/100\n",
      "Train loss: 0.000199, Val loss: 0.000210\n",
      "[INFO] EPOCH: 81/100\n",
      "Train loss: 0.000197, Val loss: 0.000178\n",
      "[INFO] EPOCH: 82/100\n",
      "Train loss: 0.000200, Val loss: 0.000212\n",
      "[INFO] EPOCH: 83/100\n",
      "Train loss: 0.000219, Val loss: 0.000196\n",
      "[INFO] EPOCH: 84/100\n",
      "Train loss: 0.000198, Val loss: 0.000194\n",
      "[INFO] EPOCH: 85/100\n",
      "Train loss: 0.000214, Val loss: 0.000229\n",
      "[INFO] EPOCH: 86/100\n",
      "Train loss: 0.000260, Val loss: 0.000234\n",
      "[INFO] EPOCH: 87/100\n",
      "Train loss: 0.000247, Val loss: 0.000203\n",
      "[INFO] EPOCH: 88/100\n",
      "Train loss: 0.000199, Val loss: 0.000195\n",
      "[INFO] EPOCH: 89/100\n",
      "Train loss: 0.000756, Val loss: 0.000199\n",
      "[INFO] EPOCH: 90/100\n",
      "Train loss: 0.000198, Val loss: 0.000198\n",
      "[INFO] EPOCH: 91/100\n",
      "Train loss: 0.000202, Val loss: 0.000225\n",
      "[INFO] EPOCH: 92/100\n",
      "Train loss: 0.000205, Val loss: 0.000171\n",
      "[INFO] EPOCH: 93/100\n",
      "Train loss: 0.000205, Val loss: 0.000177\n",
      "[INFO] EPOCH: 94/100\n",
      "Train loss: 0.000205, Val loss: 0.000257\n",
      "[INFO] EPOCH: 95/100\n",
      "Train loss: 0.000229, Val loss: 0.000207\n",
      "[INFO] EPOCH: 96/100\n",
      "Train loss: 0.000193, Val loss: 0.000206\n",
      "[INFO] EPOCH: 97/100\n",
      "Train loss: 0.000204, Val loss: 0.000190\n",
      "[INFO] EPOCH: 98/100\n",
      "Train loss: 0.000184, Val loss: 0.000177\n",
      "[INFO] EPOCH: 99/100\n",
      "Train loss: 0.000215, Val loss: 0.000170\n",
      "[INFO] EPOCH: 100/100\n",
      "Train loss: 0.000203, Val loss: 0.000190\n",
      "[INFO] total time taken to train the model:         692.70s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "# loop over our epochs\n",
    "for e in range(0, EPOCHS):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "   \n",
    "    # loop over the training set\n",
    "    for id_batch, (x, y) in enumerate(trainDataLoader):\n",
    "#         print(id_batch)\n",
    "#         print(y)\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "#         print(y.size(), y.type())\n",
    "#         print(x.size(), x.type())\n",
    "#         print(x)\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = model(x)\n",
    "#         print(pred)\n",
    "        y = torch.reshape(y,(len(y),1))\n",
    "\n",
    "        loss = lossMSE(pred, y)\n",
    "#         loss = lossMAE(pred, y)\n",
    "        \n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # add the loss to the total training loss so far and\n",
    "        totalTrainLoss += loss\n",
    "    # switch off autograd for evaluation\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        for (x, y) in valDataLoader:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = model(x)\n",
    "            y = torch.reshape(y,(len(y),1))\n",
    "            totalValLoss += lossMSE(pred, y)\n",
    "#             totalValLoss += lossMAE(pred, y)\n",
    "    \n",
    "    scheduler.step(totalValLoss)\n",
    "    \n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "    \n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Val loss: {:.6f}\".format(\n",
    "        torch.sqrt(avgTrainLoss), torch.sqrt(avgValLoss)))\n",
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: \\\n",
    "        {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f6718aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "# we can now evaluate the network on the test set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# turn off autograd for testing evaluation\n",
    "with torch.no_grad():\n",
    "    # set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # initialize a list to store our predictions\n",
    "    preds = []\n",
    "    # loop over the test set\n",
    "    for (x, y) in testDataLoader:\n",
    "        # send the input to the device\n",
    "        x = x.to(device)\n",
    "        # make the predictions and add them to the list\n",
    "        pred = model(x)\n",
    "        preds.extend(pred.argmax(axis=1).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6151c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11e28ce50>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEWCAYAAACHVDePAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABAGElEQVR4nO3dd3gc5bX48e/Zol21la3q3jG2sTEG0wk99FASegkQEgLhBshNuCH87k1ILjcdUkkIkJBAgIRQUuglxmCasY1t3BsucpVkq2v7+f0xI1myZTVrpbX2fJ5Hj3Znd2aOVtLZs2feeUdUFWOMMQObp78DMMYYk3qW7I0xJgNYsjfGmAxgyd4YYzKAJXtjjMkAluyNMSYDWLI3fUpEXhKRa3v7ucaYjlmyN50SkfpWX0kRaWp1/6rubEtVz1bVP/X2c7tDRE4WkfLe3m4X960i0uC+dlUi8oaIXNaN9fsk9v58jUxq+Po7AJP+VDWv+baIrAe+qKqv7/k8EfGparwvYztATVfVNSJSDJwN/FpEJqnqd/s7MDNwWWVveqy5+hORb4rINuARERksIs+LSIWI7HJvj2i1zpsi8kX39nUiMkdEfuo+9xMRObuHzx0rIm+JSJ2IvC4i94vIn3vwM01291stIktF5PxWj50jIsvcfWwWkW+4y4vdn7NaRHaKyNsi0un/lqpWqupjwM3At0SkyN3e9SKy3N3POhH5srs8F3gJGNbqk9UwETlKRN5z979VRH4tIlnuOiIiPxORHSJSKyIfi8hU97GA+3puFJHtIvKAiGTvaz/dfS1NerFkb/bXEKAQGA3ciPM39Yh7fxTQBPy6g/WPBlYCxcCPgd+LiPTguU8Ac4Ei4G7gmu7+ICLiB/4FvAqUAl8FHheRg92n/B74sqrmA1OBf7vLvw6UAyVAGXAX0J15SP6B8yn7KPf+DuA8IARcD/xMRA5X1QacTwJbVDXP/doCJICv4bwuxwKnAV9xt3UGcCIwESgALgWq3Md+6C4/DJgADAe+3cF+zAEs7ZK9iPzBrUKW9NL2RonIq26ltExExvTGdk2LJPAdVY2oapOqVqnqM6raqKp1wP8BJ3Ww/gZVfUhVE8CfgKE4CbPLzxWRUcCROIkqqqpzgH/24Gc5BsgDfuhu59/A88AV7uMxYIqIhFR1l6ouaLV8KDBaVWOq+rZ2Y9IpVY0BlThvmqjqC6q6Vh2zcd58PtXB+vNV9X1VjavqeuB37H7NY0A+MAkQVV2uqlvdN8kbga+p6k73d/V94PKuxm0OLGmX7IE/Amf14vYeBX6iqpNxKqcdvbhtAxWqGm6+IyI5IvI7EdkgIrXAW8AgEfHuY/1tzTdUtdG9mdfN5w4DdrZaBrCpmz8H7nY2qWqy1bINOBUvwOeAc4ANIjJbRI51l/8EWAO86rZd7uzOTt1PFCXATvf+2SLyvtsSqnb3WdzB+hPdNtI29zX/fvPz3TesXwP3AztE5EERCbn7ywHmu+2fauBld7kZgNIu2avqW7h/9M1EZLyIvCwi891+6KSubEtEpgA+VX3N3Xb9HgnB7L89K9ivAwcDR6tqCKeFALCv1kxv2AoUikhOq2Uje7CdLcDIPfrto4DNAKr6oapegNPi+TvwlLu8TlW/rqrjgPOB/xSR07qx3wuAODBXRALAM8BPgTJVHQS8yO7Xr71PDL8FVgAHua/5Xa2ej6r+UlWPAKbgtG3uwPkk0QQcoqqD3K+CVgfjbTrcASbtkv0+PAh81f2D/Qbwmy6uNxGoFpFnReQjEflJBxWm6R35OEmkWkQKge+keoequgGYB9wtIlluxf2ZztYTkWDrL5yefyPwXyLiF5GT3e38xd3uVSJS4LZdanFaWIjIeSIywW2N1OD00JPt7XOP/ReKM3T1fuBHqloFZAEBoAKIi3MQ+oxWq20HikSkoNWyfDeeercQurnVPo4UkaPdTw8NQBhIup9eHsI5HlDqPne4iJzZwX7MASztk72I5AHHAX8TkYU4/cih7mOfFZEl7Xy94q7uw+l1fgOnpzsOuK6vf4YM83MgG6dyfB+nNdAXrsI5OFkF3AP8FYh08PzhOG9Krb9G4iT3s3Hi/w3weVVd4a5zDbDebZXc5O4T4CDgdaAeeA/4jarO6mDfi0SkHqf180Wcvvm3wfmUANyK86lhF3AlrY4/uLE8Caxz2y/DcP6+rwTqcBL4X1vtK+Qu24XTkqrCaTsBfNON4X33Z3od51PZvvZjDmCSjhcvcQ+iPq+qU93+4kpVHdqD7RyDUzGd5N6/BjhGVW/p1YBN2hGRvwIrVDXlnyyMORCkfWWvqrXAJyJyCbSMG57exdU/xDk42HzQ6VRgWQrCNP3MbVeMFxGPiJyF0wf/ez+HZUzaSLtkLyJP4nwUPlicE3ZuwPm4fIOILAKW4vwjd8odovcN4A0R+RjnoNVDqYnc9LMhwJs4rZRfAjer6kf9GpExaSQt2zjGGGN6V9pV9sYYY3pfWk2EVlxcrGPGjOnvMIwx5oAxf/78SlXt9GS4tEr2Y8aMYd68ef0dhjHGHDBEZENXnmdtHGOMyQCW7I0xJgNYsjfGmAxgyd4YYzJAypK9iBwsIgtbfdWKyO2p2p8xxph9S9loHFVdiXMFHNyZJjcDz6Vqf8YYY/atr9o4pwFr3alojTHG9LG+SvaX40yXuhcRuVFE5onIvIqKij4J5h8LN1MbjvXJvowxJh2kPNmLc5X784G/tfe4qj6oqjNVdWZJSeqviLajLsxtf1nI84u2pnxfxhiTLvqisj8bWKCq2/tgX51qiiYAaIzG+zkSY4zpO32R7K9gHy2c/hCJJ9t8N8aYTJDSZC8iucCngWdTuZ/uiDYn+1iinyMxxpi+k9KJ0FS1AShK5T66KxJ3knzYKntjTAbJuDNoI1bZG2MyUOYme6vsjTEZJOOSfXPPPmyVvTEmg2RcsrfK3hiTiTIv2bsVvVX2xphMknHJPpqwyt4Yk3kyLtlHYpbsjTGZJ+OSfXNlb20cY0wmybhkb5W9MSYTZVyyjyacir75TFpjjMkEGZfsmyv7cMwqe2NM5si4ZN8yGsd69saYDJJxyb6lsreevTEmg2Rcsm+u7KPxJKraz9EYY0zfyLhk3/rArI3IMcZkioxL9tFWCT5iB2mNMRki45J962rehl8aYzJFRid7G35pjMkUGZ3srbI3xmSKVF9wfJCIPC0iK0RkuYgcm8r9dUU0nsQjzm07QGuMyRSprux/AbysqpOA6cDyFO+vU5F4gvygH7DJ0IwxmSNlyV5ECoATgd8DqGpUVatTtb+uisaT5Ad9gFX2xpjMkcrKfixQATwiIh+JyMMikrvnk0TkRhGZJyLzKioqUhiOIxJPEnIre+vZG2MyRSqTvQ84HPitqs4AGoA793ySqj6oqjNVdWZJSUkKw3FE40lC2U5lb6NxjDGZIpXJvhwoV9UP3PtP4yT/fhWJJ6yyN8ZknJQle1XdBmwSkYPdRacBy1K1v65QVaeNk918gNYqe2NMZvClePtfBR4XkSxgHXB9ivfXoXhSUWV3ZW+jcYwxGSKlyV5VFwIzU7mP7mgefdPcs7fROMaYTJFRZ9A2T4K2e5y9JXtjTGbIqGTffEA2J8uLzyN2gNYYkzEyKtk3V/YBn4eg32uVvTEmY2RUsm/u0Wf5PAR8HqvsjTEZI6OS/e7K3usme6vsjTGZIaOSfXMln9XSxrHK3hiTGTIs2e/u2WdZZW+MySAZmeytsjfGZJqMSvatR+NYz94Yk0kyKtm3buME/F5L9saYjJFRyb71aJygz2Nz4xhjMkZGJfvm0ThW2RtjMk1GJfto6wO0VtkbYzJIRiX7SOuTqvwewlbZG2MyREYl+2ib6RK8VtkbYzJGRiX7SDyBzyN4PULQKntjTAbJqGQfjSfJ8jk/csDnJZFU4glL+MaYgS+jkn0kniTgJvug39OyzBhjBrrMSvaxtpU9YFMmGGMyQkYl+2gi2ZLkmyt8q+yNMZkgpRccF5H1QB2QAOKq2q8XH4/EEy2VfdBvlb0xJnOkNNm7TlHVyj7YT6eirXr2VtkbYzJJRrVxIq1G4zRX9pbsjTGZINXJXoFXRWS+iNzY3hNE5EYRmSci8yoqKlIaTKSdyt7aOMaYTJDqZH+Cqh4OnA3cIiIn7vkEVX1QVWeq6sySkpKUBuNU9u4BWht6aYzJIClN9qq62f2+A3gOOCqV++tM256928axyt4YkwFSluxFJFdE8ptvA2cAS1K1v65oOxrHbeNYZW+MyQCpHI1TBjwnIs37eUJVX07h/jpllb0xJlOlLNmr6jpgeqq23xNtDtBaZW+MySAZNfTSqeybz6C1yt4YkzkyKtm317O30TjGmEyQMcleVdv07LO8brK3yt4YkwEyJtnHk0pSdyd5ESHg81hlb4zJCBmT7JsvSdh8YBacKRPsDFpjTCbImGTfXME3V/aAVfbGmIyRMcl+d2XvbVkW9Hst2RtjMkLGJPtI3GnXNB+gbb5tbRxjTCbImGTfXNlntU72fmvjGGMyQ8Yk++ak3nwyFUDQZwdojTGZIYOSvZPUrbI3xmSiDEr2zZV9q6GXPm/Lm4AxxgxkGZfs96zswzGr7I0xA1/GJPtoO5V9wCp7Y0yGyJhk324bx+8hYpW9MSYDZEyyj7YzGidgo3GMMRlin8leRK5udfv4PR77j1QGlQo2GscYk8k6quz/s9XtX+3x2BdSEEtK7btnn0RV+yssY4zpEx0le9nH7fbup712R+P47AImxpjM0FGy133cbu/+PomIV0Q+EpHnuxVZL4u2M+tl0J0UzZK9MWag6+iC45NEZDFOFT/evY17f1w39nEbsBwI9SzE3hGJJ/B6BJ+3nco+loBsf3+FZowxKddRsp+8vxsXkRHAucD/0fYYQJ9rfUnCZlbZG2MyxT6TvapuaH1fRIqAE4GNqjq/i9v/OfBfQP6+niAiNwI3AowaNaqLm+2+SDzZpl8Puyt7G35pjBnoOhp6+byITHVvDwWW4IzCeUxEbu9swyJyHrCjszcGVX1QVWeq6sySkpJuBd8d7VX2doDWGJMpOjpAO1ZVl7i3rwdeU9XPAEfTtaGXxwPni8h64C/AqSLy5/0Jdn+0V9nvbuNYZW+MGdg6SvaxVrdPA14EUNU6oNNSWFW/paojVHUMcDnwb1W9upPVUsap7L1tlu1u41hlb4wZ2Do6QLtJRL4KlAOHAy8DiEg2cMANXYnEE22GXYJV9saYzNFRZX8DcAhwHXCZqla7y48BHunOTlT1TVU9rycB9pZIPEnAv0fP3t889NIqe2PMwNbRaJwdwE3tLJ8FzEplUKkQiSf3quyb2zphq+yNMQPcPpO9iPyzoxVV9fzeDyd1ovEkoT1OnApaZW+MyRAd9eyPBTYBTwIfcADOh9Nah5W9jbM3xgxwHSX7IcCngSuAK4EXgCdVdWlfBNbbIvHEXj37lsrextkbYwa4fR6gVdWEqr6sqtfiHJRdA7x5IM5lD+7Qyz0q++ZK35K9MWag66iyR0QCOHPbXAGMAX4JPJf6sHpfe6NxfF4PPo9YG8cYM+B1dID2UWAqzslU3211Nu0Bqb2TqsAZa2+VvTFmoOuosr8aaMCZovhWkZbjswKoqvbrlMXdFYkn9pouAZyzaK2yN8YMdB2Nsx8wFyNX1XYnQgOr7I0xmWHAJPSOxJNKUtlr6CU4lb0le2PMQJcRyb7lYuN+D6jCwiehaRfgXJPW2jjGmIEuI5J9pPX1ZytWwN9vgo+fBqyNY4zJDJ0mexHJFRGPe3uiiJwvIgfUrJe7K3svbFnoLGyscpZZZW+MyQBdqezfAoIiMhx4FbgG+GMqg+ptzVMYZ3k9sHWhs7BxJ2CVvTEmM3Ql2YuqNgKfBX6jqpfgTH18wGjTs9+6yFnY5CT7gM9DxCp7Y8wA16VkLyLHAlfhzI8DsPfZSWmspWfvUdi62FnoVvYBq+yNMRmgK8n+duBbwHOqulRExnGAzWffnMwHN22EWIOz0K3sg1bZG2MyQIdz4wCo6mxgNoB7oLZSVW9NdWC9qblnP6h6mbOgbFqryt7G2RtjBr6ujMZ5QkRCIpILLAGWicgdqQ+t9zT37EPVS8EXhFFHt4yzD/i8NhrHGDPgdaWNM0VVa4ELgZeAsTgjcg4YzZV73s6lUDYVckshUguJGEGr7I0xGaAryd7vjqu/EPinqsYA7WwlEQmKyFwRWSQiS0Xku/sZa49F40mEJNmVS2DYYZBT6DzQtIuAz0s8qcQTlvCNMQNXV5L974D1QC7wloiMBmq7sF4EOFVVpwOHAWeJyDE9jHO/ROJJxsh2PLF6GHoYZA92HmjcaVerMsZkhE6Tvar+UlWHq+o56tgAnNKF9VRV6927fver008EqRCNJ5kqnzh3hk5vVdnvbJnj3pK9MWYg68oB2gIRuU9E5rlf9+JU+Z0SEa+ILAR2AK+p6gftPOfG5m1XVFR0N/4uicQTTPV8gnoDUDoZst1k37izZdpjO0hrjBnIutLG+QNQB1zqftUCj3Rl4+51bA8DRgBHicjUdp7zoKrOVNWZJSUlXQ68OyLxJFNlPcnSKeD1t6nsg36r7I0xA1+n4+yB8ar6uVb3v+tW612mqtUiMgs4C2f4Zp+KxpzKXoZe6ixoXdkXWGVvjBn4ulLZN4nICc13ROR4oKmzlUSkREQGubezgU8DK3oY537JbthIgTTiGT7DWZCVC94sq+yNMRmjK5X9TcCjIlLg3t8FXNuF9YYCfxIRL86bylOq+nzPwtw/hbXL3YimO99FnOq+Vc/epkwwxgxkXZkuYREwXURC7v1aEbkdWNzJeouBGb0R5P4qrVtBDC/+0im7F+YUOuPs3aGXYavsjTEDWJevVKWqte6ZtAD/maJ4UmJI4wrWMBp8gd0LWyp7t41jlb0xZgDr6WUJpVejSCVVhjWtYo13XNvlOYPdnr3zEjRZsjfGDGA9Tfb9cnJUj1RvIDdRy1r/QW2Xu5X94JwsAHY1RPshOGOM6Rv77NmLSB3tJ3UBslMWUW/bPB+ANf5JbZfnFELTTgZn+/F5hB11kX4Izhhj+sY+k72q5vdlICmzeQFRyWJbcGzb5dmFkIzjidVTmh9ge60le2PMwNXTNs6BY/N8PvGNx+vLaru81Vm0paEgO+rCfR+bMcb0kYGd7BNx2LKQVb6JBPx7XDa31Vm0ZaEAO6yyN8YMYAM72Vcsh3gTyzwHkeXd40dtXdnnB9lulb0xZgAb2MnePTi7hAktJ0+1aKnsd1EWClDdGLP5cYwxA9bAT/bBQXySKCXQUWUfCgJQYSNyjDED1ABP9gtg+BFEE7p3ZR8c5Hxv3EmZm+ztIK0xZqAauMk+2gA7lsHwI4jEk3v37L0+CBa4PXtnGgUbfmmMGagGbrLfugg06VT28eTeo3Gg5Sza5sp+e61V9saYgWngJvvNC5zvww8nEk/sXdnD7rNoc/z4vWKVvTFmwBrAyX4+FIwinl1MUmmZt74Nt7IXEUrz7cQqY8zANeCSvarywOy1VKx8jzlNozjhR7MAyM5qp43jVvYApXZilTFmABtwyf6fi7bw4EtzKYlvpTxnMp86qJivnjqB8w8btveTswuhcRcAZflB69kbYwasrlyW8IBRF47xfy8s54LSbVALl194IZePmb7vFXIKIVoH8ShloQDvrq3su2CNMaYPDajK/uevr6aiPsKXx1eDeGDoYR2vkD3Y+d60i9JQkNpw3M6iNcYMSClL9iIyUkRmicgyEVkqIrelal8AK7bV8sd313PFUaMYUrcUSiZBIK/jldrMj+OMtbe+vTFmIEplGycOfF1VF4hIPjBfRF5T1WW9uhdVtG4rf/3rc3wpsIbbRWHDuzD1os7XbTPzZTEA2+vCjCrK6dUQjTGmv6Us2avqVmCre7tORJYDw4HeTfbJBMmfH8p3kjHn/vIQlE2BGdd0vm5LG2cnZYPtxCpjzMDVJwdoRWQMMAP4oLe3XRtTfszNeAYN4e7rL8ITGgrSxeuh5+yu7EtHWRvHGDNwpTzZi0ge8Axwu6rWtvP4jcCNAKNGjer29vOyfEw7+0scMqwAT0FB91ZubuM07WJQjp8sr8fmtTfGDEgpHY0jIn6cRP+4qj7b3nNU9UFVnamqM0tKSrq9D49HuOzIUUwd3s1ED5CVC94saHLPorUTq4wxA1QqR+MI8Htguarel6r97BeRlikTAMpCdmKVMWZgSmVlfzxwDXCqiCx0v85J4f56JqcQmpyzaEvzA+ywC5gYYwagVI7GmQN08UhpP9qjsp+zxs6iNcYMPAPqDNoeyRncZjK0unCcxmi8n4MyxpjeZcm+dWWf716e0A7SGmMGGEv2zdMcq1IacsfaW9/eGDPAWLLPLoRkHCJ1dnlCY8yAZcm+1WRozW0cS/bGmIHGkn2rydBC2T4CPg8Vrds48SjMfcj5bowxByhL9q0q++azaNtU9qtfgRe/AWte65/4jDGmF1iyz3WnaKjbBjRfnrBVZb95gfO9ak0fB5Z5VJWNVY39HYYxA5Il+8FjICsftnwEuFMmtJ4MbYsl+77y5qoKTvrpLEv4xqSAJXuPF4YfDpvmAlCSH6CiubJXbXkToGptPwWYOVZtq0MV1lc19Hcoxgw4luwBRhwJ25dCtIGyUJC6SJyGSBx2roNwDfiyrbLvA1uqmwAbDWVMKliyBxh5FGgCtnxEWesTq5qr+knnQP12CO81Hb/pRZvdZG8ntRnT+yzZAwyf6Xwv/7DtiVVbPgJfECad5zxu1X1Kle+yyt6YVLFkD5BbBIXjYdOHTCjNwyMwZ3WlMxJnyDQonew8z/r2KdVS2dvcRMb0Okv2zUYc6VT2+QFOnVTGXz/4BN26CIYdDoXjALHKPoVqwzHqws5so3ZpSGN6nyX7ZiOPhIYdUL2Ba48bzaCmDUisAYbNAF8ABo2yZJ9Cm90WTm6W1yp7Y1LAkn2zEUc638vncfz4Yk4r2OzcH364871ogiX7FGpO9tNHDmJHXRhV7eeIjBlYLNk3Kz0E/DmwaS4ej3BByTbqNcjipmLn8eZkn+5J6OVvwb9u6+8ouq25X3/4qMHEEsquxlg/R2TMwGLJvpnX5/Tnyz8EYGJ8NcsYx6MflDuPF02AaL0zBDNdqcKiv8D8P8Lq1/s7mm7ZXN1Els/D5KEhwEbkGNPbLNm3NvJI2LYYwrV4dywlWnoo/1y0hZ0NUSie4DwnnVs51RvcSywKvHQHxA+c3vfmXU0MH5TNkALnPAdL9sb0rpQlexH5g4jsEJElqdpHrxtxpHMhk0VPQiLCuMNOJBpP8tcPNzmVPaR3sm+etO20bztn/77zy/6NpxvKq51kX2qXhjQmJXwp3PYfgV8Dj+7PRmKxGOXl5YTDfVDpJUfDmU8Bfud7aBiPfjZBIlnLsi0B5My/geTD8uWpj6UnokPhzL9BwQg470iIN8HSj8HjIxgMMmLECPx+f39H2a7Nu5o4bVJpy6UhrbI3pnelLNmr6lsiMmZ/t1NeXk5+fj5jxoxBRHohsk5sF0hEQbwwZCrDwjE2VDWSE/QzulgQbxYUjU99HD1RuRq0EEoOdi62UrEcsnLRwrFUVVVRXl7O2LFj+zvKvYRjCSrrIwwfnE3A52Vwjt+mTDCml/V7z15EbhSReSIyr6KiYq/Hw+EwRUVFfZPoAbJy3e85IEIo6GdoQTZ1kTh1cS+JWJpWnKoQa3RGFAH4siBvCERqkEgtRUVFffPpqAe21jhxDR+UDUBpftAqe2N6Wb8ne1V9UFVnqurMkpKSdp/TZ4kewO8mezdpiggl+QEmlOYRlywkEWXzrgaS6TYEMx4GTTpvUs3ySsCbBfUVffsadlPzGPvhg91kHwqw3Sp7Y3pVvyf7tBPIc75n5bVZnO33MiiUj0egrqGRyvo0S0Yx94IfzW9WAOKBQL7zWE/fnHYsh0j9/sfXgc3VTuzNlX1ZKMgOq+yN6VWW7Pfkz4ayqRAM7fWQx+ccPBycpeyojRCNJ/Z6TjKpNETifX8GaLTRSe5ujC38Oc70zYkeXDA9Ug+/Ownm/Kx3YtyHzbua8AgMKXBG4pSFAlTURUgm0+zTkzEHsFQOvXwSeA84WETKReSGVO2r13l3j1iprq7mN7/5jXPH5ySjoqCThLZUt60+k6qsr2pgbUU9nz7zbKqrq7u96+uuu46nn366+zE39+v3bNc09/BjPbjU35YFkIjApg+6v243lFc3MSQUxO91/hzLQkHiSWVnYw/eoIwx7UrlaJwrenub3/3XUpZt6d0LiEwZFuI7nzlkn483J/uvfOUrziUMxYsvGaUwJ5fKhhi1TTFC2X5UlfJdTdRH4gT9Xn72h7/gDebuc7u9SpMQa9p98fTW/EFAepbs3Us1suUjSCacnz8FNu9qaunXA5Tm7x5+WZwX2NdqxphusDZOJ+68807Wrl3LYYcdxpFHHcWnLvoC519+HScffThBn5fPXnQRRxxxBJOmHMLDDz3IkFCQ8SV5nH3sdBat2cTK1WuZPHkyX/rSlzjkkEM444wzaGpq2r2DWCPU72h332+88QYzZsxg2rRpfOELXyASibTENGXKFA499FC+8Y1vQKyJv/3rVaYedzrTp0/nxBNP3L0R8TgJP9rU7j465E4dQbQeKlZ2f/0u2uyeUNWsNGQnVhnT21J5UlWv66gCT5Uf/vCHLFmyhIULF/Lmm29y7rnnsGTWs4w96izqI3G+85NfMaSsmF019Xz+/NO59Yar8XqC+LyCIJRXN7J69WqefPJJHnroIS699FKeeeYZrr76amcHNVsgWgfBgjb99nA4zHXXXccbb7zBxIkT+fznP89vf/tbrrnmGp577jlWrFiBiDitolgj3/v5Q7zy8isMHz1u7/aRPweaqoFunFCl6iT7kcfApvdh8zwom7Kfr+beEkllW02YYa2SfZurhRljeoVV9t101BEzGDuiDJIJ8gI+nv3zw5x38rFce9EZbN1Szpo1u6dTGDE4m1giyYhRY5gweSqqyhFHHMH69eudJ8QjTqIH58LmraxcuZKxY8cyceJEAK699lreeustCgoKCAaD3HDDDTz77LPk5ORAtJHjj5zBdV/8Mg899BCJxB4HjpsP0ibjXf9Bd66DxiqYfrnzRrR5fndfqi7ZXhsmntQ2bZySvFbXAT6ANUbjxBPJ/g7DGMCSfbfl5rpDMuNh3nzzTebOmc3rb77N0sWLmTFjRpsTl3IDPoaGgvizslhXUc/yrXXURRLUNobZWtNEdeU2FIjhI9lU3aX9+3w+5s6dy8UXX8zzzz/PWWedBbFGHvjZD7jnnntYtnod02cczrJPNlMfjjvnA/jdRNqdETnN/fqRR8PwI1KW7JunNm7dxsnyeSjMzTqgK/t4Islp987ml/9O47mUTEaxZN+J/Px86urqdi/w+AAPNFZRU1NDYeFgRpYOZtWqlbz//vt7rV+Qk0XA52FUYQ55AR/hWJK6cJyq+gh5yRqaPHnsIh+JNRCL7q5kDz74YNavX9/ySeGxxx7jpJNOor6+npqaGs455xx+9rOfsWjRIoiHWbtpB1OmH871t36TwYVFLF21jnWV9SzbUktF2ANI95J9+VwIhKBkkpPsty9zhnf2si1VzieaEa0qe3AO0m4/gHv2i8qr2VoTZvaqvc8KN6Y/HFA9+/5QVFTE8ccfz9SpU8nOzqasrAxyBkPjLs769Ok88MADTJ48mYMPPphjjjlmn9sZlJPFoJwsykIBaiTKIYUguxL4BpUiSS9SvYuqqoqWM3ODwSCPPPIIl1xyCfF4nCOPPJKbbrqJnTt3csEFFxAOO1dzuu9H3wfgG9/5PktXrQNVzjrjdC46/Tgao0kq6yNsq4tS5A9CvGaf8e1l04dOkvd4nO+agK2LYPSx+/V6trH+Hc59/kIelLsZNujMNg+VhYLsOICvRTt7VSUASzfX0BRNkJ2VmpFMvSaZhFiDcxLeAPBxeQ0Th+QR8KX5696HLNl3wRNPPNF2QawJGqsIJOt56aWX2l2nuS9fXFzMkiW7Z3m+4447nBtVa8Djh0CIbCBZm0Vuop7/+fGvGVviDNk87bTT+Oijj9psd+jQocydO3f3gvrtULuFBx99kq11ccYW55IfdA7EhrK9BPweVm2rp4ksp7JX3Xss/p4idbBjKZzoxjr8COf75nm9m+znP4JPo1wfnEVO1i1tHioLBVixrXeH2fal2asqyPJ5iMaTLC6v5uhxRf0dUsfm/wFe/x587WPnGM0BrHxXI+ffP4dvnjWJm05K00kL+4G1cXrCn+1Mp9BQufc0BKrOPDUdiUechJpb5CReETzZg8iTMLF4jLU7GthW00R9ONb5WaTRBtTjZ1t9gkHZ/pZE3yzg8zIox091zO+Mx6/e0PnPt3mB89wRRzn380qhYFTv9u3DtbD8eRJ4OJt39moRlYWCVNZHSaTyLNqmXVC7pdc3u7MhyuLyaq48ahQA8zbs6vV99LoVL0CkBta/09+R7Ld31lSiCnNWV/Z3KGnFkn1P5RY7lXKkVfWpCtUbnflkGjro1TZWcctdP+CwE87isMMOc75OPJs//vXvjM1L4vUIFXVR1lU2sGxrLesrG2iKtjOSJhZGwzXUkocAQwuy934OTv+7SbOcO1sWdv6zlbufHEYcsXvZiB4epE3uYzTKsn9AvIk/Bq4iVxthxfN7xZxIKlUNKezb//Ua+MOZ+46xh95eXYEqXHDYMCaU5jE/3ZN9LAwb3nNur5vVv7H0gnfXVgHw4fqdhGN7T2mSqSzZ91SwwGnD1LdK6nXbnMsCerOgphwaqvZeT5PQuJP77/0BCxctYuHChe7XIq6/4nNkJ+qYUJrHlGH5jCnKpTA3i4ZonNU76tlQ1UCT+8ebVCVRuxXFw+Z4PmWhIH5f+7/OgN9LIDsXRWja2IWEvelDKJ4I2YN3Lxt+hPNGVt+NA47r34GfjIeV7bS6Fv0FLRzPvY3nsCtrGHz0WJuHU35i1Yb3YP3bzs9UPrfz53fDW6sqGZTj59ARg5g5ejDzN+xK73l+yudCvAkN5MO6N/s7mv2iqry7torivACReJIFG9P8jbYPWbLvKfE41X20zqmMGqugfhvkFELJZOdAV81GaNy5e51E3HlDSMYgp3iP7YnzBhKphWQSr8dDKNvPsEHZTBriJPP6cJzV2+tYsa2WNVsq8ISrqdQQ/qwsivOyOgy3JJRNDC/bV+w9YqiN5pOpmls4zVr69l2s7hsq4ZkbnDe/F+9o26bZtR42zKFpyqU0xpR1Iy6ET95ylrtSfmLV2z+FnCLwBmDpc7222WRSmb2qgk8dVILXIxw+ejA1TTHWVqR25tD9su5NkuLl/qYzoHIV1Gzu74h6bM2OeirqItx00ji8HuG9te0UXBnKkv3+yCkCBGo2QfUmyMqHgpHOCJbBY52+fvUG5yDqzk9g+xLndiC/3Vk1CQ5yKv9oXZvFXo+HslCQg4fkU5ofJNvvZZSvFhUP+UXDGF+S1+l89UG/F/VkMah6GTUNHQzBrFrrJOiRR7ZdPnQ6Kl7WL57d+fTDySQ892Xnje7sHzuvT+uZMxc/BcDG4Z8BoH7yJYDAwidbnlLWcnnCFFT2Wz6CNa/DsbfAQZ+GpX935v7pBcu31VJZH+Gkic48RTNHO5+O0rlvr+tms9Qzkedjzu98wZu99+bX195Z4/TpzzxkCNOGF7TcN5bs94/X77Q6ovXOVAeFY5yKH5xJwwrHOWev1m5xD8gWO+PWiya0PyImkOdcDjFc3e7ufF4PQwqCjM4Xgok6PPmlZAcDeLp4YRJfVoBBUs+3HnmB+2etYc7qSmoaY9Q0xVi6pYZXlm5jzqwXnSfvUdknfTlsD45j4+K3Oe3e2fz5/Q0ktyyCP5wF/77HOeDa7N1fOMn0rB/A0V+GqRfDO79w3vBUnQu6j/kUf16ZxCMwZtzBMO5kWPhES/+8OC+ACKkZfvn2vRAogCO/CIdc5Hwi29jJJ54uah5Xf+JBzie3scW5FOVmpW/fvqkatizg35HJXHz2GdR4BrFx3gs8+t76/o6sR95dW8XIwmxGFuZw/IQiFpXXUB/pxpnjA5gNvdxfeWVONR4a7p5w1YrH6yT2aL1T9Xs6eW8Vj1PxN+50RuwEC9w5c4Jtn1e31XlTyC3tVqhed+6d4rplPPBKnOM8SzjOs5Rq8pidmM4iHc/3fG8y3ZvNo0t9fLk4ic/rDB/8xt8WcUzdSC4KzGVaWYh5/3yAS7IexpeVjXfjeyQ//D3VR9xK3aDJjHrjf5EpF8LMLzg7PuN/nb79K/8Pjr8Ndq5j/ZSbefyNjVx/3FhGF+XCjKudts/6t2Dcyfi9Hopys3q/st+xApb/yxlWGiyAiWeBLxuWPgtjjt/vzb+1qoLJQ0MtxxxEnFZO2ib79XMQTfIB03jgqFHkbj+dU5e/zqH/WEJdOM4tp0zo7wi7LJFU3l9XxdlThwJw3Phi7p+1lrmfVHHqpLJ+jq7/WbLfX/4gFO6+iHdeXh719a36sx5vy7jl9evXc95557UZd7+X0AinjxyucT4R1G5xDvj6s52k5PE6ff38Yd2fctjrB4+P7/n+yHezqxBNEPNk401GuM33HImsEIKy0jeFn7y6mteWV3DPhVP58SsreWtVBRdNP4Hslf/m8cEPIlueZR5T+Er9rQyXnXwt8SQnzrmbQmCHbwjBM+4j1PyJIzQMTroDXr8bqjeivmxuWzySoaEsvn6GM/cPk851XqeP/uxU+TjXou31K1bNuc/5tHX0zc79QB5MPNMZHXT2j/drGuf6SJx563fxxRPGOsdx4mHIdg7SvrZsO5X1kbSbsjmxdhYRApRNOYFQ0A8TTiW09GlunhTmJ6+s5KixhRw5prC/w+ySpVtqqA3HOW6Cc07DEaMHk+Xz8O4aS/ZwoCX7l+6EbR/37jaHTIOzf9i729wfXh+Ehjpf8YiT9KMNzolczZOleXxOS6i7RJyWSuUq5PDPw4TT8I840vnkse5NvGvegPVzmPSp6/ildwb/8/clnPerOXgEfvS5aZwyaiys/B6y9Fk45hbGHHsXF79XTkKVFblnQeNHDFv7F/5zyyk0/P5jHvr8TMaVuHMJHfMVWPAYbP+YVaVns2hjkoc/P5XcgPsn6M+GaZc4yb5qLRSNpywUYHtHbZxk0pkiOpC37+e0tnMdfPw3J5ZcJyGEYwk2lpzOxGV/5/u/eYjwyBP4n/OmtFxIpUP1FbDxXdi2BLYvxVO+mI/8leR9GIG57nDOw6/liGnfAWD+hl2ceciQrsXaR5pWvMHcxGQunOkWLO4b7dfGb+EfWw/hO/9Yyr++egJeT/pew7jZO2ucg7HHjnd+t0G/lyNGDeYdO0gLHGjJvh/ceeedjBw5kltucc7wvPvuu/H5fMyaNYtdu3YRi8W45557uOCCC7q13XA4zM0338y8efPw+Xzcd999nHLKKSxdupTrr7+eaDRKMpnkmWeeYdiwYVx6zaWUl5eTiMf4n/93F5ddOa1nP9Bnf7f3suzBTu/6kIsAEOB84Jixhfzs9dWcNqmU06c4M30y8wYYfRxMu5hi4L/OmtRqQ+OBi7lrXRVfeXwBF97/Dr++8nBOnFjiHNM45yfoE5fy3S1Hce60oc42Wzv6JljyDDx0Klz6J8pChSzZ18VqPnkLXv1vqFwNVz3deQtmx3L4+83OcNlj/4Oaphj/98Iy/r5wC554LvMDAabVzOKr5SOpaYpx36WHdZzgKlY5Y/Sbdjrtt6IJrPVN4COmcdVxk50L11SugQV/YnrZdLK8w9Iv2ddsJq/+ExZnXctXJ7jFQ8FwKJ5I1obZ3HXuxfzHEx/x5NyNXH3M6P6NtQveXVvJxLI8SvN3tz2Pn1DET19dxc6GKIW5HY9YG+gOrGTfDxX4ZZddxu23396S7J966ileeeUVbr31VkKhEJWVlRxzzDGcf/75nY6Iae3+++9HRPj4449ZsWIFZ5xxBqtWreKBBx7gtttu46qrriIajZJIJHjxxRcZNmwYL7zwAgA1Nd2Y42Y/lIaC/OCzrd5UPF44775O1ztmXBH/uOV4vvToPK59ZC4TSvKYMizElKFjmFP8FB/viPPGZ9qZG7/4IPjSv+HJK+Gxz3LGmNt5qv5w4gnn2AHg9Nxf/w6setkZ+ZQ/FJ64FD7/z7YngTWLR+Dt+9yDsvnw2Qd5c6uXO595i4r6CFccNZKTJ5biX3wOn9n4FuVnfJcfvbqWnCwv379oWvu/05pyeOwi5/W47kVqCqfx2Lzt/PbNtRw3oZjPf3qm87xkEuq343/1Ti4s+wnz1rczAqsf1S5/nRCQN+X0tm9s406Bjx7j3MsK+fO4Qn766krOnTaUwWmcLCPxBB+u38nlR45qs/zY8cXAKt5bW8W5hw7tn+DShI3G6cSMGTPYsWMHW7ZsYdGiRQwePJghQ4Zw1113ceihh3L66aezefNmtm/f3q3tzpkzp+UCJpMmTWL06NGsWrWKY489lu9///v86Ec/YsOGDWRnZzNt2jRee+01vvnNb/L2229TUJD+c5eMLMzhmZuP42unT2RUYQ4ffrKTH7y0grc3hrnz7EktBzD3UjgOvvgaTDyTUz+5l9/4fs5bP76E9feeSsNPDkV/eyzxT+aw7JD/5JEZT/HIQb+iwTeY+KMXUr1u/u4LvSfisOJF+N2JMPuHxCZdwLrL3+TOFeO47pEPCWX7+PtXjueeC6dx+pQysqZfDI1V3Dx6C/9xygSenLuJe15YvveF4xt3wmOfhUgtOy96kntXFXPCve/x01dXccy4Iv773Mm7n+vxwGcfgrwy7qr/AZs2b0mrMzq3L3yFCg1x0vEntX1g3MkQa0TKP+Tu8w+hLhzn3tdSd6Wy3vDRxmrCsSTHjW87B9H0EQXkBXy8u9aGYB5YlX0/ueSSS3j66afZtm0bl112GY8//jgVFRXMnz8fv9/PmDFj2sxjvz+uvPJKjj76aF544QXOOeccfve733HqqaeyYMECXnzxRf77v/+b0047jW9/+9u9sr9Uyg34uPW0g1ru72qIsqWmiSlDO6lwA/lw2eOEX/sep33wG2pi+WwIF/JxcihrkjN5tOnT7JofAj4B4PfyDZ7K+i5Zf7qQLyVv5njvCj7DbIqpZpuUcHfym7y8YDosWIJH4OaTx3P76Qe1nRFxwunOiKl3f8XXT/02DeFR/H7OJ6zaXseIwdmEsv0U+WOc+9FNlDSs46ve/+GVh3cgsoOzpw7hKydPYOrwdt6Ec4vg0j8R+v2Z/NjzK5aUn8LMsT043tKZeBSqVrvXCvY5nzr82c6nn/Y+nahStP1dPg7O4KQhe8Q95gRntNe6N5l02qe45pjRPPreeq44ahSHDEvPQuPdtVV4hL0mnPN5PRw9trBlCoVMltJkLyJnAb8AvMDDqppGR0K77rLLLuNLX/oSlZWVzJ49m6eeeorS0lL8fj+zZs1iw4YuTC62h0996lM8/vjjnHrqqaxatYqNGzdy8MEHs27dOsaNG8ett97Kxo0bWbx4MZMmTaKwsJCrr76aQYMG8fDDD6fgp0y9wblZXW8FeDwEz7wbzvgOxSKE4km8W2tJVjXwq9wApaEApfkBAj4v5bsaWb9+Eoe9cSUPR39EAi/L84/lmdDZLMs9muGhXL6V76wzdVgBB5W1M42vPwjHfgVm/whZ+2++nVvC50bMZPH2XArKKyhMVDJGtlLKLn4Quov8USfz30PyOfngEiaUdjIt8PAjaDz1/zjl9f9i85+O4QPvSLb5R7IzMIJ47hB8oVKCBWXkDi7DRxxPtAGJ1eOL1ZMfqyAU2UFedBvBSBV1nhDbpYTyxGB2xLIZG13FQeHFjG5cgj+59zDVcFYh1cVH0FA2k0jpdOrjXhoiMZoqN3KO7sI/4ZS94w2GYMSRsPyfkFfGN0ONFAdXMPuPr7Jg6EFI0XiyyyYwOJRPrkQJJarJje8ky5NEc0tJ5pS0TJWs4TqkYRtSv4NYNEK9BqhNBKhNZoE3i7zsLPKzswgFs/BEa4jtKidZ44xCa6yvpbahidrGJuobI9RpNnX+Qur9xYQDxeQXDGJYYQHDiwtYuGwrJw1RCiLbIJzYfZKcCGcMbeQ3K9eyYj4UJGvwNFUhkRqiucMIh8YSzh9DwpNFm89wmiS4axX5W98jd+t7BHetojFnGDtzxrEtMIaKrBGEcrIpzAtSlBcglJtNzBMgLNmEJZu4N5u8nBzygn7ygj48IuxsiFJZH6GyPkJDJEHA7yHo8xL0QZ43wUEjujeUurtkr4+pvbVhES+wCvg0UA58CFyhqsv2tc7MmTN13rx5bZYtX76cyZMn72ONvjNt2jSKi4uZNWsWlZWVfOYzn6G+vp6ZM2fy/vvv89JLLzFmzJi9h1620nro5b4O0P7whz/ksccew+/3M2TIEJ544gk+/PBD7rjjDjweD36/n9/+9rfMnDmz2z9DuryWKVO5xpnIa/L5kN/DoXb1FbD2DeeksDVvuMNch6KhYSTyhiHTLsY75bzub1eVD/52L8Et71LYtJGS6CaC2vVPg7WaTaUWMFjqGSy7/76SCKsZzQfJScyLTyCCHw9JfCQISSOHe1YzU1Yy2rP3Re2TCLVfXsCgoeP23uE7v4DXOv70GFY/QYnt8zFFyJZuXDBnD3H1kBAvSfGBeAkkG/HQ+5d5TKiwRYuJ48FHEo8kyaeJkDhTfGxMlrBUxzBcKpkgW8iRrp37kVQhgp8IfqL4ieEloR5i+BCUPAmTSxO5EmEHhZTe/UmP4heR+araaUJIZbI/FrhbVc90738LQFV/sK910jnZDwT2WnZTMgnofo293ydVZ56k+u3QUEm4ZjuN1TtIig8J5KOBXCQrn3CwlPpgGfXkEIknKM4LMDQ7Tn5khzP/UNmUlgnrEkklkVRnkrykEk8o9dE49eE44apNeCtXkJsl5GT5yAv4yR5chmf4jH3HV7/daQl5s5zRVLEm2LmOWOUaGreuItJQQ6N/MI2+wdR5BxFLClmRnQQilQQiVYgmCQdLiARLiWYX4/MHyfNEyZMwORKGRIxwNEZTNEYkGiPmy4fQMKRgGP5BwykrLqQkL7D7IHky4cwmW78d6rZDrJFoJExFTR3VdfWMK80nOyvLaUF5vDjjyhRUWba1lmrNIR4sIhooJJGVT17TVvLqPyG//hNy6jeCgIoPFS9Jb4DaomlUlx5NU85wPCKEsv0U5vgoim0jWL+J6oYwuxoiVDdEaAiHCWiUbJoIJsP4Eo3Eo2Hi0SY02oQko+T4lGyvEvQ4Aw5i3lyi3hwinmxigUImnv/1Hv0pdTXZp7KNMxzY1Op+OXD0nk8SkRuBGwFGjRq158PG9J/OznjeHyK7z6cAgu5X1w2GkoPbLPF6ZK/hogU57vUNhkwB2hkB1VF8+XsME/UFYPjh+IcfTsH0bgXbOzxeJ6b8IeAOrMnCSTTDO1l1ymHtLT2kh4HkAwdRCqS28dK7+v0Arao+CDwITmXfz+H0io8//phrrrmmzbJAIMAHH3zQTxEZYzJdKpP9ZmBkq/sj3GXdpqrdGsPe36ZNm8bChQv7O4w2UtWuM8YcGFI5zv5D4CARGSsiWcDlwD+7u5FgMEhVVZUlq/2gqlRVVREMdq9RYIwZOFJW2atqXET+A3gFZ+jlH1R1aXe3M2LECMrLy6mo6MYVksxegsEgI0aM6O8wjDH9JKU9e1V9EXhxf7bh9/sZO3Zs5080xhizTzZdgjHGZABL9sYYkwEs2RtjTAZI2Rm0PSEiFUD3J5pxFAPpOrVdOscG6R1fOscG6R1fOscG6R1fOscGbeMbraolna2QVsl+f4jIvK6cMtwf0jk2SO/40jk2SO/40jk2SO/40jk26Fl81sYxxpgMYMneGGMywEBK9g/2dwAdSOfYIL3jS+fYIL3jS+fYIL3jS+fYoAfxDZievTHGmH0bSJW9McaYfbBkb4wxGeCAT/YicpaIrBSRNSJyZxrE8wcR2SEiS1otKxSR10Rktft9cD/FNlJEZonIMhFZKiK3pVl8QRGZKyKL3Pi+6y4fKyIfuL/jv7qzqPYLEfGKyEci8nwaxrZeRD4WkYUiMs9dli6/20Ei8rSIrBCR5SJybBrFdrD7mjV/1YrI7WkU39fc/4clIvKk+3/S7b+7AzrZu9e5vR84G+cyPFeISDcux5MSfwTO2mPZncAbqnoQ8IZ7vz/Ega+r6hTgGOAW9/VKl/giwKmqOh04DDhLRI4BfgT8TFUnALuAG/opPoDbgOWt7qdTbACnqOphrcZgp8vv9hfAy6o6CZiO8xqmRWyqutJ9zQ4DjgAagefSIT4RGQ7cCsxU1ak4MwhfTk/+7lT1gP0CjgVeaXX/W8C30iCuMcCSVvdXAkPd20OBlf0doxvLP3AuCJ928QE5wAKcS1lWAr72fud9HNMInH/6U4HncS5ymhaxuftfDxTvsazff7dAAfAJ7oCQdIqtnVjPAN5Jl/jYfXnXQpxZip8HzuzJ390BXdnT/nVuO7scZX8oU9Wt7u1tQFl/BgMgImOAGcAHpFF8bptkIbADeA1YC1Sratx9Sn/+jn8O/BeQdO8XkT6xASjwqojMd6/tDOnxux0LVACPuC2wh0UkN01i29PlwJPu7X6PT1U3Az8FNgJbgRpgPj34uzvQk/0BR5234n4d7yoiecAzwO2qWtv6sf6OT1UT6nycHgEcBUzqr1haE5HzgB2qOr+/Y+nACap6OE5b8xYRObH1g/34u/UBhwO/VdUZQAN7tET6++8OwO17nw/8bc/H+is+9zjBBThvmMOAXPZuE3fJgZ7se+06tym2XUSGArjfd/RXICLix0n0j6vqs+kWXzNVrQZm4XxEHSQizRfa6a/f8fHA+SKyHvgLTivnF2kSG9BSBaKqO3B6zkeRHr/bcqBcVT9w7z+Nk/zTIbbWzgYWqOp29346xHc68ImqVqhqDHgW52+x2393B3qy75Xr3PaBfwLXurevxemV9zkREeD3wHJVva/VQ+kSX4mIDHJvZ+McT1iOk/Qv7s/4VPVbqjpCVcfg/J39W1WvSofYAEQkV0Tym2/j9J6XkAa/W1XdBmwSkYPdRacBy9Ihtj1cwe4WDqRHfBuBY0Qkx/3/bX7tuv93198HRHrhAMY5wCqc3u7/S4N4nsTprcVwKpobcHq7bwCrgdeBwn6K7QScj6KLgYXu1zlpFN+hwEdufEuAb7vLxwFzgTU4H7ED/fw7Phl4Pp1ic+NY5H4tbf5fSKPf7WHAPPd3+3dgcLrE5saXC1QBBa2WpUV8wHeBFe7/xGNAoCd/dzZdgjHGZIADvY1jjDGmCyzZG2NMBrBkb4wxGcCSvTHGZABL9sYYkwEs2ZsBSUQSe8xk2GuTWInIGGk1q2kXnp8rIq+7t+e0OhnGmD5jf3RmoGpSZ9qFdHAs8J576nuD7p7TxJg+Y5W9ySjunO8/dud9nysiE9zlY0Tk3yKyWETeEJFR7vIyEXlOnDn2F4nIce6mvCLykDvP+KvuGb977mu8O6nbn4ErcSawmu5+0ijtm5/YGIclezNQZe/Rxrms1WM1qjoN+DXOTJYAvwL+pKqHAo8Dv3SX/xKYrc4c+4fjnJ0KcBBwv6oeAlQDn9szAFVd6366mI8zT82fgBvUmTu9v+eBMRnGzqA1A5KI1KtqXjvL1+NcIGWdOyncNlUtEpFKnLnLY+7yrapaLCIVwAhVjbTaxhjgNXUuaoGIfBPwq+o9+4jlQ1U9UkSeAW5T1fLe/nmN6YxV9iYT6T5ud0ek1e0E7Rz/EpEH3AO5B7ntnLOA50Xkaz3cpzE9ZsneZKLLWn1/z739Ls5slgBXAW+7t98AboaWC6sUdHUnqnoTziRW/wtcCLzgtnB+tl/RG9MDNhrHDFTZbjXd7GVVbR5+OVhEFuNU51e4y76KcyWlO3CuqnS9u/w24EERuQGngr8ZZ1bTrjoJeBT4FDC7Jz+IMb3BevYmo7g9+5mqWtnfsRjTl6yNY4wxGcAqe2OMyQBW2RtjTAawZG+MMRnAkr0xxmQAS/bGGJMBLNkbY0wG+P9dk6nPRWLEfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"][40:], label=\"train_loss\")\n",
    "plt.plot(H[\"val_loss\"][40:], label=\"val_loss\")\n",
    "\n",
    "\n",
    "plt.title(\"Training Loss Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss MSE\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(args[\"plot\"])\n",
    "# serialize the model to disk\n",
    "# torch.save(model, args[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dacf5763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3323e-08)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchmetrics import MeanSquaredError\n",
    "mean_squared_error = MeanSquaredError()\n",
    "        \n",
    "with torch.no_grad():\n",
    "    # set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # initialize a list to store our predictions\n",
    "    preds = []\n",
    "    loss = 0\n",
    "    # loop over the test set\n",
    "    for (x, y) in testDataLoader:\n",
    "        # send the input to the device\n",
    "        x = x.to(device)\n",
    "        # make the predictions and add them to the list\n",
    "        pred = model(x).flatten()\n",
    "#         print(y)\n",
    "#         print(pred)\n",
    "        loss += mean_squared_error(pred, y)        \n",
    "        \n",
    "        \n",
    "#         print(y-pred)\n",
    "#         print(y.numpy(), (pred.flatten().cpu()).numpy())\n",
    "        plt.scatter(np.log(y.numpy()), (pred.flatten().cpu()).numpy(), color = 'black')\n",
    "#         preds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "print(loss/testSteps)       \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34c0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4222b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n",
      "tensor(9.3019) tensor(109.2334)\n",
      "tensor(2.8340) tensor(96.5046)\n",
      "tensor(2.8775) tensor(98.2734)\n",
      "torch.Size([20, 100])\n",
      "tensor(0.0757) tensor(1.1249)\n",
      "tensor(-0.0005) tensor(0.9791)\n",
      "tensor(2.3842e-10) tensor(1.0003)\n"
     ]
    }
   ],
   "source": [
    "# m = nn.BatchNorm1d(100)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm1d(100, affine=False)\n",
    "\n",
    "input = 100*torch.randn(20, 100)\n",
    "\n",
    "print(input.shape)\n",
    "\n",
    "print(input[0].mean(), input[0].std())\n",
    "print(input[1].mean(), input[1].std())\n",
    "print(input.mean(), input.std())\n",
    "\n",
    "output = m(input)\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "print(output[0].mean(),output[0].std())\n",
    "print(output[1].mean(),output[1].std())\n",
    "print(output.mean(),output.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e1ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
