{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51ba08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import flatten\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import BatchNorm2d\n",
    "from torchvision.transforms import ToTensor\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22df8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "torch.Size([2, 64, 50])\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "        target_954 = np.load('data_segment/Y_natur_954.npz')\n",
    "        for j in range(3000):\n",
    "            self.data.append([\"data_segment/natur_X/954_\" + str(j) + '.npz',target_954['arr_0'][j]])\n",
    "#         print(self.data)\n",
    "\n",
    "        target_9_7 = np.load('data_segment/Y_natur_9_7.npz')\n",
    "#         print(target_9_7['arr_0'])\n",
    "        for j in range(3000):\n",
    "            self.data.append([\"data_segment/natur_X/9_7_\" + str(j) + '.npz',target_9_7['arr_0'][j]])\n",
    "\n",
    "        \n",
    "        target_Air = np.load('data_segment/Y_natur_Air.npz')\n",
    "#         print(target_Air['arr_0'])\n",
    "        for j in range(3000):\n",
    "            self.data.append([\"data_segment/natur_X/Air_\" + str(j) + '.npz',target_Air['arr_0'][j]])\n",
    "        \n",
    "        temp = np.load('data_segment/natur_X/954_0.npz')\n",
    "        self.img_dim = temp['arr_0'].shape  \n",
    "#         print(self.img_dim)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)    \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.data[idx]\n",
    "        \n",
    "        img = np.load(img_path)\n",
    "        img_tensor = torch.from_numpy(img['arr_0'])\n",
    "        \n",
    "        target_tensor = torch.tensor(target)\n",
    "#         print(target_tensor, target)\n",
    "        \n",
    "#         img_tensor = img_tensor.permute(2, 0, 1)\n",
    "#         class_id = torch.tensor([class_id])\n",
    "        \n",
    "        return img_tensor, target_tensor\n",
    "\n",
    "    \n",
    "data = CustomDataset()\n",
    "print(len(data))\n",
    "\n",
    "print(data[1][0].size())\n",
    "print(data[1][0].type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254b538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300\n",
      "1350\n",
      "1350\n"
     ]
    }
   ],
   "source": [
    "Train_split = 0.7\n",
    "Val_split = 0.15\n",
    "Test_split = 0.15\n",
    "(trainData, valData, testData) = random_split(data, [Train_split, Val_split, Test_split],\\\n",
    "                                              generator=torch.Generator().manual_seed(42))\n",
    "print(len(trainData))\n",
    "print(len(valData))\n",
    "print(len(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f1d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# print(testDataLoader.dataset[0])\n",
    "\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "print(trainSteps)\n",
    "\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE\n",
    "print(valSteps)\n",
    "\n",
    "testSteps = len(testDataLoader.dataset) // BATCH_SIZE\n",
    "print(testSteps)\n",
    "\n",
    "\n",
    "# print(trainDataLoader.dataset)\n",
    "# print(trainDataLoader.dataset[1])\n",
    "# print(trainDataLoader.dataset[1][0].type())\n",
    "# print(trainDataLoader.dataset[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7687455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.norm1 = BatchNorm2d(2)\n",
    "\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels = 2, out_channels = 8,\\\n",
    "                            kernel_size = (16, 20), stride = (16,10))#16 - height, 20 - width \n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) #stride = step\n",
    "        \n",
    "#         self.norm2 = BatchNorm2d(8)\n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=32, out_features=8)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc2 = Linear(in_features=8, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "#         print(x)\n",
    "        x = self.norm1(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = flatten(x, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3fb73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20256705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the LeNet model...\n",
      "LeNet(\n",
      "  (norm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(2, 8, kernel_size=(16, 20), stride=(16, 10))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define training hyperparameters\n",
    "INIT_LR = 0.001\n",
    "\n",
    "# initialize the LeNet model\n",
    "print(\"[INFO] initializing the LeNet model...\")\n",
    "\n",
    "model = LeNet().to(device)\n",
    "\n",
    "if str(device) == 'cpu':\n",
    "    model.type(torch.DoubleTensor)\n",
    "elif str(device) == 'cuda':\n",
    "    model.type(torch.cuda.DoubleTensor)\n",
    "# model.type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "\n",
    "print(model)\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(opt, 'min')\n",
    "\n",
    "\n",
    "\n",
    "lossMSE = nn.MSELoss()\n",
    "# lossMAE = nn.L1Loss()\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [],\"val_loss\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d3da5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n",
      "[INFO] EPOCH: 1/10\n",
      "Train loss: 0.022098, Val loss: 0.005180\n",
      "[INFO] EPOCH: 2/10\n",
      "Train loss: 0.006979, Val loss: 0.006324\n",
      "[INFO] EPOCH: 3/10\n",
      "Train loss: 0.006999, Val loss: 0.004797\n",
      "[INFO] EPOCH: 4/10\n",
      "Train loss: 0.007321, Val loss: 0.006793\n",
      "[INFO] EPOCH: 5/10\n",
      "Train loss: 0.005448, Val loss: 0.002963\n",
      "[INFO] EPOCH: 6/10\n",
      "Train loss: 0.004452, Val loss: 0.004230\n",
      "[INFO] EPOCH: 7/10\n",
      "Train loss: 0.005244, Val loss: 0.002861\n",
      "[INFO] EPOCH: 8/10\n",
      "Train loss: 0.004630, Val loss: 0.003297\n",
      "[INFO] EPOCH: 9/10\n",
      "Train loss: 0.004569, Val loss: 0.004812\n",
      "[INFO] EPOCH: 10/10\n",
      "Train loss: 0.003596, Val loss: 0.002788\n",
      "[INFO] total time taken to train the model:         117.91s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "# loop over our epochs\n",
    "for e in range(0, EPOCHS):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "   \n",
    "    # loop over the training set\n",
    "    for id_batch, (x, y) in enumerate(trainDataLoader):\n",
    "#         print(id_batch)\n",
    "#         print(y)\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "#         print(y.size(), y.type())\n",
    "#         print(x.size(), x.type())\n",
    "#         print(x)\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = model(x)\n",
    "#         print(pred)\n",
    "        y = torch.reshape(y,(len(y),1))\n",
    "\n",
    "        loss = lossMSE(pred, y)\n",
    "#         loss = lossMAE(pred, y)\n",
    "        \n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # add the loss to the total training loss so far and\n",
    "        totalTrainLoss += loss\n",
    "    # switch off autograd for evaluation\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        for (x, y) in valDataLoader:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = model(x)\n",
    "            y = torch.reshape(y,(len(y),1))\n",
    "            totalValLoss += lossMSE(pred, y)\n",
    "#             totalValLoss += lossMAE(pred, y)\n",
    "    \n",
    "    scheduler.step(totalValLoss)\n",
    "    \n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "    \n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Val loss: {:.6f}\".format(\n",
    "        torch.sqrt(avgTrainLoss), torch.sqrt(avgValLoss)))\n",
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: \\\n",
    "        {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb16310",
   "metadata": {},
   "source": [
    "$$\\bf OPTUNA$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09d281dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_activ = {'relu': nn.ReLU(), 'elu': nn.ELU(), 'logsigm': nn.LogSigmoid(), 'tanh': nn.Tanh()}\n",
    "\n",
    "class ConvNet(Module):\n",
    "    def __init__(self, trial):\n",
    "        # call the parent constructor\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.norm1 = BatchNorm2d(2)\n",
    "        \n",
    "        out_ch = trial.suggest_int(\"out_ch\", 2, 16, log = True)\n",
    "        self.conv1 = Conv2d(in_channels = 2, out_channels = out_ch,\\\n",
    "                            kernel_size = (16, 20), stride = (16,10))#16 - height, 20 - width \n",
    "        \n",
    "        activ_1 = trial.suggest_categorical(\"activ_1\", ['relu', 'elu', 'logsigm', 'tanh'])\n",
    "        self.act1 = dict_activ[activ_1]\n",
    "        \n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) #stride = step\n",
    "         \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        \n",
    "        n_neur = trial.suggest_int(\"n_neur\",2,128,log = True)\n",
    "        self.fc1 = Linear(in_features = 4*out_ch, out_features = n_neur)\n",
    "        \n",
    "        \n",
    "        activ_2 = trial.suggest_categorical(\"activ_2\", ['relu', 'elu', 'logsigm', 'tanh'])\n",
    "        self.act2 = dict_activ[activ_2]\n",
    "        \n",
    "        self.fc2 = Linear(in_features = n_neur, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "#         print(x)\n",
    "        x = self.norm1(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = flatten(x, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.act2(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fcabbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = ConvNet(trial).to(device)\n",
    "    \n",
    "    if str(device) == 'cpu':\n",
    "        model.type(torch.DoubleTensor)\n",
    "    elif str(device) == 'cuda':\n",
    "        model.type(torch.cuda.DoubleTensor)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "\n",
    "    # try RMSprop and SGD\n",
    "    '''\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\"])\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr,momentum=momentum)\n",
    "    '''\n",
    "    #try Adam, AdaDelta adn Adagrad\n",
    "    \n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\",\"Adagrad\"])\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "#     scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    batch_size=trial.suggest_int(\"batch_size\", 4, 256, log = True)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    \n",
    "    trainDataLoader = DataLoader(trainData, shuffle = True, batch_size = batch_size)\n",
    "    valDataLoader = DataLoader(valData, batch_size = batch_size)\n",
    "#     testDataLoader = DataLoader(testData, batch_size = batch_size)\n",
    "    \n",
    "    trainSteps = len(trainDataLoader.dataset) // batch_size\n",
    "    valSteps = len(valDataLoader.dataset) // batch_size\n",
    "    \n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "       \n",
    "        totalTrainLoss = 0\n",
    "        totalValLoss = 0\n",
    "    \n",
    "        for id_batch, (x, y) in enumerate(trainDataLoader):\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, torch.reshape(y,(len(y),1)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            totalTrainLoss += loss    \n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (x, y) in valDataLoader:\n",
    "                # send the input to the device\n",
    "                (x, y) = (x.to(device), y.to(device))\n",
    "                # make the predictions and calculate the validation loss\n",
    "                pred = model(x)\n",
    "                totalValLoss += criterion(pred, torch.reshape(y,(len(y),1)))\n",
    "    #             totalValLoss += lossMAE(pred, y)\n",
    "        \n",
    "        avgTrainLoss = totalTrainLoss / trainSteps\n",
    "        avgValLoss = totalValLoss / valSteps\n",
    "        \n",
    "        \n",
    "        trial.report(torch.sqrt(avgValLoss), epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avgValLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-06 15:43:03,325]\u001b[0m A new study created in memory with name: no-name-91c64837-8d1d-4ab6-8d63-45b394f197e5\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 15:45:09,299]\u001b[0m Trial 0 finished with value: 0.025910444083480463 and parameters: {'out_ch': 9, 'activ_1': 'elu', 'n_neur': 17, 'activ_2': 'relu', 'optimizer': 'Adagrad', 'lr': 9.32321115649712e-05, 'batch_size': 145}. Best is trial 0 with value: 0.025910444083480463.\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 15:46:49,729]\u001b[0m Trial 1 finished with value: 0.0004588513120081346 and parameters: {'out_ch': 2, 'activ_1': 'elu', 'n_neur': 73, 'activ_2': 'elu', 'optimizer': 'Adadelta', 'lr': 0.0006989123919447076, 'batch_size': 11}. Best is trial 1 with value: 0.0004588513120081346.\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 15:48:30,097]\u001b[0m Trial 2 finished with value: 0.00010066948366899458 and parameters: {'out_ch': 3, 'activ_1': 'elu', 'n_neur': 4, 'activ_2': 'elu', 'optimizer': 'Adam', 'lr': 2.796156953623737e-05, 'batch_size': 8}. Best is trial 2 with value: 0.00010066948366899458.\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 15:50:08,464]\u001b[0m Trial 3 finished with value: 2.926897299337614e-06 and parameters: {'out_ch': 15, 'activ_1': 'logsigm', 'n_neur': 101, 'activ_2': 'relu', 'optimizer': 'Adam', 'lr': 0.00011467173288751423, 'batch_size': 21}. Best is trial 3 with value: 2.926897299337614e-06.\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 15:51:56,112]\u001b[0m Trial 4 finished with value: 0.0017964751856170264 and parameters: {'out_ch': 2, 'activ_1': 'tanh', 'n_neur': 25, 'activ_2': 'logsigm', 'optimizer': 'Adagrad', 'lr': 0.0001220285084091352, 'batch_size': 4}. Best is trial 3 with value: 2.926897299337614e-06.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('sqrt_MSE: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56623961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becd998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f229ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
