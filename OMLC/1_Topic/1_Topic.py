					### https://habr.com/ru/company/ods/blog/322626/
					#   Открытый курс машинного обучения. 
					#   Тема 1. Первичный анализ данных с Pandas

# импортируем Pandas и Numpy
import pandas as pd
import numpy as np




# Прочитаем данные (метод read_csv)
df = pd.read_csv('../mlcourse.ai/data/telecom_churn.csv')

# Gосмотрим на первые 5 строк с помощью метода head:
df.head()

# По умолчанию Pandas выводит всего 20 столбцов и 60 строк, 
# поэтому если ваш датафрейм больше, воспользуйтесь функцией set_option:
pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 100)
#print(df.head())

# Посмотрим на размер данных, названия признаков и их типы.
#print(df.shape)

# Видим, что в таблице 3333 строки и 20 столбцов. Выведем названия столбцов:
#print(df.columns)

# Чтобы посмотреть общую информацию по датафрейму и всем признакам, воспользуемся методом info:
#print(df.info())
# bool, int64, float64 и object — это типы признаков. Видим, что 1 признак — логический (bool), 
# 3 признака имеют тип object и 16 признаков — числовые. Также с помощью метода info удобно
# быстро посмотреть на пропуски в данных, в нашем случае их нет, в каждом столбце по 3333 наблюдения.

# Изменить тип колонки можно с помощью метода astype. Применим этот метод к признаку Churn и переведём его в int64:
#df['Churn'] = df['Churn'].astype('int64')
#print(df.info())

# Метод describe показывает основные статистические характеристики данных по каждому числовому 
# признаку (типы int64 и float64): число непропущенных значений, среднее, 
# стандартное отклонение, диапазон, медиану, 0.25 и 0.75 квартили.
#print(df.describe())
#print(df.describe(include=['object', 'bool']))

# Для категориальных (тип object) и булевых (тип bool) признаков можно воспользоваться 
# методом value_counts. Посмотрим на распределение данных по нашей целевой переменной — Churn:
#print(df['Churn'].value_counts())
# 2850 пользователей из 3333 — лояльные, значение переменной Churn у них — 0

# Посмотрим на распределение пользователей по переменной Area code. 
# Укажем значение параметра normalize=True, чтобы посмотреть не абсолютные частоты, а относительные.
# print(df['Area code'].value_counts(normalize=True))

									# Сортировка

# DataFrame можно отсортировать по значению какого-нибудь из признаков. В нашем случае,
# например, по Total day charge (ascending=False для сортировки по убыванию):
# print(df.sort_values(by='Total day charge', ascending=False).head())

# Сортировать можно и по группе столбцов:
# print(df.sort_values(by=['Churn', 'Total day charge'], ascending=[True, False]).head())

							# Индексация и извлечение данных

# Для извлечения отдельного столбца можно использовать конструкцию вида DataFrame['Name']. 
# Воспользуемся этим для ответа на вопрос: какова доля людей нелояльных пользователей в нашем датафрейме?
# print(df['Churn'].mean()) # выводит: 0.14491449144914492

# Очень удобной является логическая индексация DataFrame по одному столбцу. 
# Выглядит она следующим образом: df[P(df['Name'])], где P — это некоторое логическое условие, 
# проверяемое для каждого элемента столбца Name. Итогом такой индексации является DataFrame, 
# состоящий только из строк, удовлетворяющих условию P по столбцу Name.

# Воспользуемся этим для ответа на вопрос: каковы средние значения числовых признаков среди нелояльных пользователей?
# print(df[df['Churn'] == 1].mean())

# Скомбинировав предыдущие два вида индексации, ответим на вопрос: сколько 
# в среднем в течение дня разговаривают по телефону нелояльные пользователи?
# print(df[df['Churn'] == 1]['Total day minutes'].mean()) # выводит: 206.91407867494823

# Какова максимальная длина международных звонков среди лояльных пользователей (Churn == 0),
# не пользующихся услугой международного роуминга ('International plan' == 'No')?
# print(df[(df['Churn'] == 0) & (df['International plan'] == 'No')]['Total intl minutes'].max()) # выводит: 18.899999999999999

# Датафреймы можно индексировать как по названию столбца или строки, так и по порядковому номеру.
# Для индексации по названию используется метод loc, по номеру — iloc.
# В первом случае мы говорим «передай нам значения для id строк от 0 до 5 и для столбцов от State до Area code»,
# print(df.loc[0:5, 'State':'Area code'])
# а во втором — «передай нам значения первых пяти строк в первых трёх столбцах».
# print(df.iloc[0:5, 0:3])

# Если нам нужна первая или последняя строчка датафрейма, пользуемся конструкцией df[:1] или df[-1:]:
#print(df[-1:])

						# Применение функций к ячейкам, столбцам и строкам

# Применение функции к каждому столбцу: apply
# print(df.apply(np.max))
# Метод apply можно использовать и для того, чтобы применить функцию к каждой строке. Для этого нужно указать axis=1.

# Применение функции к каждой ячейке столбца: map
# Например, метод map можно использовать для замены значений в колонке, 
# передав ему в качестве аргумента словарь вида {old_value: new_value}:
# d = {'No' : False, 'Yes' : True}
# df['International plan'] = df['International plan'].map(d)
# print(df.head())

# Аналогичную операцию можно провернуть с помощью метода replace:
# d = {'No' : False, 'Yes' : True}
# df = df.replace({'Voice mail plan': d})
# print(df.head())

								# Группировка данных

# В общем случае группировка данных в Pandas выглядит следующим образом:
# print(df.groupby(by=grouping_columns)[columns_to_show].function())
# К датафрейму применяется метод groupby, который разделяет данные по grouping_columns – признаку или набору признаков.
# Выбираем нужные нам столбцы (columns_to_show).
# К полученным группам применяется функция или несколько функций.
# columns_to_show = ['Total day minutes', 'Total eve minutes', 'Total night minutes']
# print(df.groupby(['Churn'])[columns_to_show].describe(percentiles=[]))

# Сделаем то же самое, но немного по-другому, передав в agg список функций:
# columns_to_show = ['Total day minutes', 'Total eve minutes', 'Total night minutes']
# print(df.groupby(['Churn'])[columns_to_show].agg([np.mean, np.std, np.min, np.max]))

								# Сводные таблицы

# Допустим, мы хотим посмотреть, как наблюдения в нашей выборке распределены в контексте двух признаков — Churn 
# и International plan. Для этого мы можем построить таблицу сопряженности, воспользовавшись методом crosstab:
# print(pd.crosstab(df['Churn'], df['International plan']))
# print(pd.crosstab(df['Churn'], df['Voice mail plan'], normalize=True))

# В Pandas за сводные таблицы отвечает метод pivot_table, который принимает в качестве параметров:
# values – список переменных, по которым требуется рассчитать нужные статистики,
# index – список переменных, по которым нужно сгруппировать данные,
# aggfunc — то, что нам, собственно, нужно посчитать по группам — сумму, среднее, максимум, минимум или что-то ещё.

# Давайте посмотрим среднее число дневных, вечерних и ночных звонков для разных Area code:
# print(df.pivot_table(['Total day calls', 'Total eve calls', 'Total night calls'], ['Area code'], aggfunc='mean').head(10))

							# Преобразование датафреймов

# Например, мы хотим посчитать общее количество звонков для всех пользователей. 
# Создадим объект total_calls типа Series и вставим его в датафрейм:
# total_calls = df['Total day calls'] + df['Total eve calls'] + df['Total night calls'] + df['Total intl calls']
# df.insert(loc=len(df.columns), column='Total calls', value=total_calls)
# loc - номер столбца, после которого нужно вставить данный Series
# мы указали len(df.columns), чтобы вставить его в самом конце
# print(df.head())

# Добавить столбец из имеющихся можно и проще, не создавая промежуточных Series:
# df['Total charge'] = df['Total day charge'] + df['Total eve charge'] + df['Total night charge'] + df['Total intl charge']
# print(df.head())

# Чтобы удалить столбцы или строки, воспользуйтесь методом drop, передавая в качестве аргумента нужные индексы 
# и требуемое значение параметра axis (1, если удаляете столбцы, и ничего или 0, если удаляете строки):
# избавляемся от созданных только что столбцов
# df = df.drop(['Total charge', 'Total calls'], axis=1) 

# а вот так можно удалить строчки
# print(df.drop([1, 2]).head())

						# Первые попытки прогнозирования оттока

# Посмотрим, как отток связан с признаком "Подключение международного роуминга" (International plan). 
# Сделаем это с помощью сводной таблички crosstab, а также путем иллюстрации с Seaborn (как именно 
# строить такие картинки и анализировать с их помощью графики – материал следующей статьи).	
# print(pd.crosstab(df['Churn'], df['International plan'], margins=True))

# Далее посмотрим на еще один важный признак – "Число обращений в сервисный центр" (Customer service calls). 
# Также построим сводную таблицу и картинку.
# print(pd.crosstab(df['Churn'], df['Customer service calls'], margins=True))

# Добавим теперь в наш DataFrame бинарный признак — результат сравнения Customer service calls > 3.
# И еще раз посмотрим, как он связан с оттоком.
# df['Many_service_calls'] = (df['Customer service calls'] > 3).astype('int')
# print(pd.crosstab(df['Many_service_calls'], df['Churn'], margins=True))

# Объединим рассмотренные выше условия и построим сводную табличку для этого объединения и оттока.
# d = {'No' : False, 'Yes' : True}
# df['International plan'] = df['International plan'].map(d)
# print(pd.crosstab(df['Many_service_calls'] & df['International plan'], df['Churn']))

